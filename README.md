# NLP_HuggingFace_Course
My notes on learning NLP HuggingFace course!
## Table of Contents
- [Chapter 1. Transformer models](#chapter-1---transformer-models)
- [Chapter 2. Using ðŸ¤— Transformers](#chapter-2---using--transformers)
- [Chapter 3. Fine-tuning a pretrained model](#chapter-3---fine-tuning-a-pretrained-model)
- [Chapter 4. Sharing models and tokenizers](#chapter-4---sharing-models-and-tokenizers)
- [Chapter 5. The ðŸ¤— Datasets library](#chapter-5---the--datasets-library)
- [Chapter 6. The ðŸ¤— Tokenizers library](#chapter-6---the--tokenizers-library)
- [Chapter 7. Main NLP tasks](#chapter-7---main-nlp-tasks)
- [Chapter 8. How to ask for help](#chapter-8---how-to-ask-for-help)
- [Chapter 9. Building and sharing demos](#chapter-9---building-and-sharing-demos)

-------------------------------------------------------------------------------------

## Chapter 1 - Transformer models
1, Working with pipelines:
- The most basic object in the ðŸ¤— Transformers library is the pipeline() function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer.
